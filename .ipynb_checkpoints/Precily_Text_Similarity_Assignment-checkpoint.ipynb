{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51598ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings, string\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader as api\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcf214f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challenges tv viewing the number of ...</td>\n",
       "      <td>gardener wins double in glasgow britain s jaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap boss arrested over drug find rap mogul mar...</td>\n",
       "      <td>amnesty chief laments war failure the lack of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burn-out worries robinson england coach...</td>\n",
       "      <td>hanks greeted at wintry premiere hollywood sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hearts of oak 3-2 cotonsport hearts of oak set...</td>\n",
       "      <td>redford s vision of sundance despite sporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rocks super bowl crowds sir paul mcca...</td>\n",
       "      <td>mauresmo opens with victory in la amelie maure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challenges tv viewing the number of ...   \n",
       "1  rap boss arrested over drug find rap mogul mar...   \n",
       "2  player burn-out worries robinson england coach...   \n",
       "3  hearts of oak 3-2 cotonsport hearts of oak set...   \n",
       "4  sir paul rocks super bowl crowds sir paul mcca...   \n",
       "\n",
       "                                               text2  \n",
       "0  gardener wins double in glasgow britain s jaso...  \n",
       "1  amnesty chief laments war failure the lack of ...  \n",
       "2  hanks greeted at wintry premiere hollywood sta...  \n",
       "3  redford s vision of sundance despite sporting ...  \n",
       "4  mauresmo opens with victory in la amelie maure...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Precily_Text_Similarity.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6949af",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "df['text1'] = df['text1'].apply(lambda x: stem_words(x))\n",
    "df['text2'] = df['text2'].apply(lambda x: stem_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "080a534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "df['text1'] = df['text1'].apply(lambda x: lemmatize_words(x))\n",
    "df['text2'] = df['text2'].apply(lambda x: lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f8e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in stopwords.words('english') and not word.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1646fced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b093980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text1'] = df['text1'].apply(lambda x: text_process(x))\n",
    "df['text2'] = df['text2'].apply(lambda x: text_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "527f9f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c3a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(a,b):\n",
    "    intersection = set(a).intersection(set(b))\n",
    "    union = set(a).union(set(b))\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "523092ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similarity(df['text1'][0],df['text2'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b595761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer=<function text_process at 0x000001F31510F0D0>)\n",
      "CountVectorizer(analyzer=<function text_process at 0x000001F31510F0D0>)\n"
     ]
    }
   ],
   "source": [
    "bow_transformer1 = CountVectorizer(analyzer=text_process).fit(df['text1'])\n",
    "bow_transformer2 = CountVectorizer(analyzer=text_process).fit(df['text2'])\n",
    "print(bow_transformer1)\n",
    "print(bow_transformer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9af2b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 38)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_transformer1.vocabulary_), len(bow_transformer2.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79f611fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t167\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t95\n",
      "  (0, 12)\t17\n",
      "  (0, 13)\t32\n",
      "  (0, 14)\t23\n",
      "  (0, 15)\t88\n",
      "  (0, 16)\t24\n",
      "  (0, 17)\t22\n",
      "  (0, 18)\t23\n",
      "  (0, 19)\t56\n",
      "  (0, 20)\t3\n",
      "  (0, 21)\t19\n",
      "  (0, 22)\t39\n",
      "  (0, 23)\t31\n",
      "  (0, 24)\t55\n",
      "  (0, 25)\t70\n",
      "  (0, 26)\t12\n",
      "  (0, 27)\t4\n",
      "  (0, 28)\t55\n",
      "  (0, 29)\t35\n",
      "  (0, 30)\t72\n",
      "  (0, 31)\t29\n",
      "  (0, 32)\t3\n",
      "  (0, 33)\t13\n",
      "  (0, 34)\t1\n",
      "  (0, 35)\t6\n",
      "  (0, 36)\t2\n"
     ]
    }
   ],
   "source": [
    "text4 = df['text1'][3]\n",
    "bow4 = bow_transformer1.transform([text4])\n",
    "print(bow4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "431b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 38)\n"
     ]
    }
   ],
   "source": [
    "bow_text1 = bow_transformer1.transform(df['text1'])\n",
    "print(bow_text1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21291499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 38)\n"
     ]
    }
   ],
   "source": [
    "bow_text2 = bow_transformer2.transform(df['text2'])\n",
    "print(bow_text2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d74dc3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer1 = TfidfTransformer().fit(bow_text1)\n",
    "tfidf_transformer2 = TfidfTransformer().fit(bow_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cceddc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 36)\t0.013055846780139978\n",
      "  (0, 35)\t0.022250077435161244\n",
      "  (0, 34)\t0.004138953140290266\n",
      "  (0, 33)\t0.04820850110951602\n",
      "  (0, 32)\t0.011128746445899422\n",
      "  (0, 31)\t0.10754204093661267\n",
      "  (0, 30)\t0.2670009292219349\n",
      "  (0, 29)\t0.1297921183717739\n",
      "  (0, 28)\t0.20395904315564473\n",
      "  (0, 27)\t0.0214428335884421\n",
      "  (0, 26)\t0.04450015487032249\n",
      "  (0, 25)\t0.2595842367435478\n",
      "  (0, 24)\t0.20395904315564473\n",
      "  (0, 23)\t0.11495873341499975\n",
      "  (0, 22)\t0.14462550332854807\n",
      "  (0, 21)\t0.07088246164593452\n",
      "  (0, 20)\t0.012989252523926654\n",
      "  (0, 19)\t0.20766738939483825\n",
      "  (0, 18)\t0.08529196350145143\n",
      "  (0, 17)\t0.0815836172622579\n",
      "  (0, 16)\t0.08900030974064498\n",
      "  (0, 15)\t0.3263344690490316\n",
      "  (0, 14)\t0.08529196350145143\n",
      "  (0, 13)\t0.11866707965419329\n",
      "  (0, 12)\t0.06304188606629019\n",
      "  (0, 11)\t0.3522928927233863\n",
      "  (0, 10)\t0.011089971430165385\n",
      "  (0, 9)\t0.010339242840822743\n",
      "  (0, 6)\t0.008505999327078297\n",
      "  (0, 4)\t0.009006977779888707\n",
      "  (0, 0)\t0.6192938219453212\n"
     ]
    }
   ],
   "source": [
    "tfidf4 = tfidf_transformer1.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab69022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 38)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf4.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f032b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_text1 = tfidf_transformer1.transform(bow_text1)\n",
    "tfidf_text2 = tfidf_transformer2.transform(bow_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4458ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of non-zero values in TFIDF of text 1: 85549\n",
      "Amount of non-zero values in TFIDF of text 2: 85711\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount of non-zero values in TFIDF of text 1:\",tfidf_text1.nnz)\n",
    "print(\"Amount of non-zero values in TFIDF of text 2:\",tfidf_text2.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66c02195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TFIDF of text 1: (3000, 38)\n",
      "Shape of TFIDF of text 2: (3000, 38)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of TFIDF of text 1:\",tfidf_text1.shape)\n",
    "print(\"Shape of TFIDF of text 2:\",tfidf_text2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e9a20ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of text 1: 75.04%\n",
      "Sparsity of text 2: 75.19%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity of text 1:\",str(np.round((tfidf_text1.nnz/(tfidf_text1.shape[0]*tfidf_text1.shape[1]))*100,2)) + '%')\n",
    "print(\"Sparsity of text 2:\",str(np.round((tfidf_text2.nnz/(tfidf_text2.shape[0]*tfidf_text2.shape[1]))*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38ccc49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.9785293861463167, 0.9887675564206015, 0.988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.970073371768313, 0.9818744094402776, 0.9865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.9643083804078563, 0.9701381455232274, 0.962...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.9759967531076594, 0.982251639784895, 0.9806...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.9834646778322373, 0.9882872871600276, 0.994...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "1  [0.9785293861463167, 0.9887675564206015, 0.988...\n",
       "2  [0.970073371768313, 0.9818744094402776, 0.9865...\n",
       "3  [0.9643083804078563, 0.9701381455232274, 0.962...\n",
       "4  [0.9759967531076594, 0.982251639784895, 0.9806...\n",
       "5  [0.9834646778322373, 0.9882872871600276, 0.994..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similarity = [[]]\n",
    "for i in range(tfidf_text1.shape[0]):\n",
    "    cos_similarity.append(cosine_similarity(tfidf_text1[i],tfidf_text2))\n",
    "cos_similarity = pd.DataFrame(cos_similarity)\n",
    "cos_similarity.drop(index=cos_similarity.index[0], \n",
    "        axis=0, \n",
    "        inplace=True)\n",
    "cos_similarity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6c532bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64264209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978529</td>\n",
       "      <td>0.970073</td>\n",
       "      <td>0.964308</td>\n",
       "      <td>0.975997</td>\n",
       "      <td>0.983465</td>\n",
       "      <td>0.974899</td>\n",
       "      <td>0.975446</td>\n",
       "      <td>0.981171</td>\n",
       "      <td>0.974635</td>\n",
       "      <td>0.971818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976139</td>\n",
       "      <td>0.977350</td>\n",
       "      <td>0.982670</td>\n",
       "      <td>0.970279</td>\n",
       "      <td>0.969073</td>\n",
       "      <td>0.979111</td>\n",
       "      <td>0.982001</td>\n",
       "      <td>0.961637</td>\n",
       "      <td>0.979260</td>\n",
       "      <td>0.975768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988768</td>\n",
       "      <td>0.981874</td>\n",
       "      <td>0.970138</td>\n",
       "      <td>0.982252</td>\n",
       "      <td>0.988287</td>\n",
       "      <td>0.981370</td>\n",
       "      <td>0.978910</td>\n",
       "      <td>0.989982</td>\n",
       "      <td>0.980058</td>\n",
       "      <td>0.979575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981408</td>\n",
       "      <td>0.985446</td>\n",
       "      <td>0.983493</td>\n",
       "      <td>0.978564</td>\n",
       "      <td>0.971599</td>\n",
       "      <td>0.977041</td>\n",
       "      <td>0.990116</td>\n",
       "      <td>0.969929</td>\n",
       "      <td>0.981814</td>\n",
       "      <td>0.987708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.988882</td>\n",
       "      <td>0.986596</td>\n",
       "      <td>0.962266</td>\n",
       "      <td>0.980612</td>\n",
       "      <td>0.994628</td>\n",
       "      <td>0.977163</td>\n",
       "      <td>0.977388</td>\n",
       "      <td>0.986011</td>\n",
       "      <td>0.980424</td>\n",
       "      <td>0.985989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982220</td>\n",
       "      <td>0.980308</td>\n",
       "      <td>0.975918</td>\n",
       "      <td>0.981216</td>\n",
       "      <td>0.977847</td>\n",
       "      <td>0.976986</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.960132</td>\n",
       "      <td>0.980092</td>\n",
       "      <td>0.977371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984609</td>\n",
       "      <td>0.973072</td>\n",
       "      <td>0.960169</td>\n",
       "      <td>0.976659</td>\n",
       "      <td>0.985454</td>\n",
       "      <td>0.973015</td>\n",
       "      <td>0.982949</td>\n",
       "      <td>0.994004</td>\n",
       "      <td>0.984009</td>\n",
       "      <td>0.982400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988786</td>\n",
       "      <td>0.983359</td>\n",
       "      <td>0.991103</td>\n",
       "      <td>0.984215</td>\n",
       "      <td>0.978290</td>\n",
       "      <td>0.985069</td>\n",
       "      <td>0.983268</td>\n",
       "      <td>0.969183</td>\n",
       "      <td>0.984444</td>\n",
       "      <td>0.984504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991294</td>\n",
       "      <td>0.981296</td>\n",
       "      <td>0.956340</td>\n",
       "      <td>0.986461</td>\n",
       "      <td>0.989491</td>\n",
       "      <td>0.980954</td>\n",
       "      <td>0.970051</td>\n",
       "      <td>0.984327</td>\n",
       "      <td>0.974304</td>\n",
       "      <td>0.979598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974879</td>\n",
       "      <td>0.974234</td>\n",
       "      <td>0.981270</td>\n",
       "      <td>0.971890</td>\n",
       "      <td>0.969613</td>\n",
       "      <td>0.974051</td>\n",
       "      <td>0.984597</td>\n",
       "      <td>0.962306</td>\n",
       "      <td>0.977571</td>\n",
       "      <td>0.974417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         0         0         0         0         0         0  \\\n",
       "0  0.978529  0.970073  0.964308  0.975997  0.983465  0.974899  0.975446   \n",
       "1  0.988768  0.981874  0.970138  0.982252  0.988287  0.981370  0.978910   \n",
       "2  0.988882  0.986596  0.962266  0.980612  0.994628  0.977163  0.977388   \n",
       "3  0.984609  0.973072  0.960169  0.976659  0.985454  0.973015  0.982949   \n",
       "4  0.991294  0.981296  0.956340  0.986461  0.989491  0.980954  0.970051   \n",
       "\n",
       "          0         0         0  ...         0         0         0         0  \\\n",
       "0  0.981171  0.974635  0.971818  ...  0.976139  0.977350  0.982670  0.970279   \n",
       "1  0.989982  0.980058  0.979575  ...  0.981408  0.985446  0.983493  0.978564   \n",
       "2  0.986011  0.980424  0.985989  ...  0.982220  0.980308  0.975918  0.981216   \n",
       "3  0.994004  0.984009  0.982400  ...  0.988786  0.983359  0.991103  0.984215   \n",
       "4  0.984327  0.974304  0.979598  ...  0.974879  0.974234  0.981270  0.971890   \n",
       "\n",
       "          0         0         0         0         0         0  \n",
       "0  0.969073  0.979111  0.982001  0.961637  0.979260  0.975768  \n",
       "1  0.971599  0.977041  0.990116  0.969929  0.981814  0.987708  \n",
       "2  0.977847  0.976986  0.986111  0.960132  0.980092  0.977371  \n",
       "3  0.978290  0.985069  0.983268  0.969183  0.984444  0.984504  \n",
       "4  0.969613  0.974051  0.984597  0.962306  0.977571  0.974417  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_matrix = pd.DataFrame()\n",
    "for i in range(cos_similarity.shape[0]):\n",
    "    cosine_similarity_matrix = pd.concat([cosine_similarity_matrix,(pd.DataFrame(cos_similarity.iloc[i].values.tolist()).T)],axis=1)\n",
    "cosine_similarity_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29092326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e56de7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    707\n",
       "0    707\n",
       "0    707\n",
       "0    614\n",
       "0    707\n",
       "    ... \n",
       "0    586\n",
       "0    707\n",
       "0    614\n",
       "0    707\n",
       "0    707\n",
       "Length: 3000, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_matrix.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfb93ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881484386605357"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_matrix.iloc[707].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1472663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04d21cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = []\n",
    "\n",
    "for idx in df.index:\n",
    "    t1 = df['text1'][idx]\n",
    "    t2 = df['text2'][idx]\n",
    "    \n",
    "    if t1 == t2:\n",
    "        similarity.append(1)\n",
    "    else:\n",
    "        t1_words = word_tokenize(t1)\n",
    "        t2_words = word_tokenize(t2)\n",
    "        vocab = wv.vocab\n",
    "        \n",
    "        if len(t1_words and t2_words) == 0:\n",
    "            similarity.append(0)\n",
    "        else:\n",
    "            for word in t1_words.copy():\n",
    "                if word not in vocab:\n",
    "                    t1_words.remove(word)\n",
    "            for word in t2_words.copy():\n",
    "                if word not in vocab:\n",
    "                    t2_words.remove(word)\n",
    "            similarity.append(wv.n_similarity(t1_words,t2_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "871d8326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.738640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.667202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.775820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.658866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.865341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.738640\n",
       "1  0.667202\n",
       "2  0.775820\n",
       "3  0.658866\n",
       "4  0.865341"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = pd.DataFrame(similarity)\n",
    "similarity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a94ab57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challeng tv view number european bro...</td>\n",
       "      <td>garden win doubl glasgow britain jason garden ...</td>\n",
       "      <td>0.738640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap bos arrest drug find rap mogul marion suge...</td>\n",
       "      <td>amnesti chief lament war failur lack public ou...</td>\n",
       "      <td>0.667202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burnout worri robinson england coach an...</td>\n",
       "      <td>hank greet wintri premier hollywood star tom h...</td>\n",
       "      <td>0.775820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heart oak cotonsport heart oak set ghanaian co...</td>\n",
       "      <td>redford vision sundanc despit sport corduroy c...</td>\n",
       "      <td>0.658866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rock super bowl crowd sir paul mccart...</td>\n",
       "      <td>mauresmo open victori la ameli mauresmo maria ...</td>\n",
       "      <td>0.865341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challeng tv view number european bro...   \n",
       "1  rap bos arrest drug find rap mogul marion suge...   \n",
       "2  player burnout worri robinson england coach an...   \n",
       "3  heart oak cotonsport heart oak set ghanaian co...   \n",
       "4  sir paul rock super bowl crowd sir paul mccart...   \n",
       "\n",
       "                                               text2         0  \n",
       "0  garden win doubl glasgow britain jason garden ...  0.738640  \n",
       "1  amnesti chief lament war failur lack public ou...  0.667202  \n",
       "2  hank greet wintri premier hollywood star tom h...  0.775820  \n",
       "3  redford vision sundanc despit sport corduroy c...  0.658866  \n",
       "4  mauresmo open victori la ameli mauresmo maria ...  0.865341  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,similarity],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "636c74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['text1','text2','Similarity Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6593cc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>broadband challeng tv view number european bro...</td>\n",
       "      <td>garden win doubl glasgow britain jason garden ...</td>\n",
       "      <td>0.738640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap bos arrest drug find rap mogul marion suge...</td>\n",
       "      <td>amnesti chief lament war failur lack public ou...</td>\n",
       "      <td>0.667202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player burnout worri robinson england coach an...</td>\n",
       "      <td>hank greet wintri premier hollywood star tom h...</td>\n",
       "      <td>0.775820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heart oak cotonsport heart oak set ghanaian co...</td>\n",
       "      <td>redford vision sundanc despit sport corduroy c...</td>\n",
       "      <td>0.658866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir paul rock super bowl crowd sir paul mccart...</td>\n",
       "      <td>mauresmo open victori la ameli mauresmo maria ...</td>\n",
       "      <td>0.865341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  broadband challeng tv view number european bro...   \n",
       "1  rap bos arrest drug find rap mogul marion suge...   \n",
       "2  player burnout worri robinson england coach an...   \n",
       "3  heart oak cotonsport heart oak set ghanaian co...   \n",
       "4  sir paul rock super bowl crowd sir paul mccart...   \n",
       "\n",
       "                                               text2  Similarity Score  \n",
       "0  garden win doubl glasgow britain jason garden ...          0.738640  \n",
       "1  amnesti chief lament war failur lack public ou...          0.667202  \n",
       "2  hank greet wintri premier hollywood star tom h...          0.775820  \n",
       "3  redford vision sundanc despit sport corduroy c...          0.658866  \n",
       "4  mauresmo open victori la ameli mauresmo maria ...          0.865341  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdf431e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('similarity_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db3c1ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.0.0 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.0.0 requires pyqtwebengine<5.13, which is not installed.\n",
      "dash 2.0.0 requires dash-table==5.0.0, which is not installed.\n",
      "anaconda-project 0.10.2 requires ruamel-yaml, which is not installed.\n",
      "spyder 5.0.0 requires jedi==0.17.2, but you have jedi 0.18.1 which is incompatible.\n",
      "spyder 5.0.0 requires parso==0.7.0, but you have parso 0.8.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting voila\n",
      "  Downloading voila-0.3.5-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: jupyter-server<2.0.0,>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from voila) (1.13.5)\n",
      "Collecting websockets>=9.0\n",
      "  Downloading websockets-10.2-cp38-cp38-win_amd64.whl (97 kB)\n",
      "Requirement already satisfied: jupyter-client<8,>=6.1.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from voila) (7.1.2)\n",
      "Requirement already satisfied: traitlets<6,>=5.0.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from voila) (5.1.1)\n",
      "Collecting nbconvert<7,>=6.4.5\n",
      "  Downloading nbconvert-6.5.0-py3-none-any.whl (561 kB)\n",
      "Requirement already satisfied: nbclient<0.6,>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from voila) (0.5.11)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from voila) (2.10.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client<8,>=6.1.3->voila) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client<8,>=6.1.3->voila) (4.9.2)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client<8,>=6.1.3->voila) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client<8,>=6.1.3->voila) (0.3)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client<8,>=6.1.3->voila) (1.5.1)\n",
      "Requirement already satisfied: tornado>=4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client<8,>=6.1.3->voila) (6.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8,>=6.1.3->voila) (302)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (0.13.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (21.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (2.11.3)\n",
      "Requirement already satisfied: nbformat in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (5.1.3)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (1.8.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (3.5.0)\n",
      "Collecting pywinpty<2\n",
      "  Downloading pywinpty-1.1.6-cp38-none-win_amd64.whl (1.4 MB)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (21.3.0)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (0.58.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (0.13.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from anyio<4,>=3.1.0->jupyter-server<2.0.0,>=0.3.0->voila) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from anyio<4,>=3.1.0->jupyter-server<2.0.0,>=0.3.0->voila) (1.2.0)\n",
      "Requirement already satisfied: json5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.3.0->voila) (0.9.6)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.3.0->voila) (2.27.1)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.3.0->voila) (3.2.0)\n",
      "Requirement already satisfied: babel in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.3.0->voila) (2.9.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->jupyter-server<2.0.0,>=0.3.0->voila) (1.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->jupyterlab-server<3,>=2.3.0->voila) (21.4.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->jupyterlab-server<3,>=2.3.0->voila) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->jupyterlab-server<3,>=2.3.0->voila) (0.18.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->jupyterlab-server<3,>=2.3.0->voila) (59.4.0)\n",
      "Collecting tinycss2\n",
      "  Downloading tinycss2-1.1.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert<7,>=6.4.5->voila) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert<7,>=6.4.5->voila) (0.1.2)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-2.1.1-cp38-cp38-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: bleach in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert<7,>=6.4.5->voila) (4.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert<7,>=6.4.5->voila) (4.10.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert<7,>=6.4.5->voila) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert<7,>=6.4.5->voila) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert<7,>=6.4.5->voila) (2.11.2)\n",
      "Collecting jinja2\n",
      "  Downloading Jinja2-3.1.1-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\hp\\anaconda3\\lib\\site-packages (from argon2-cffi->jupyter-server<2.0.0,>=0.3.0->voila) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<2.0.0,>=0.3.0->voila) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<2.0.0,>=0.3.0->voila) (2.21)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from babel->jupyterlab-server<3,>=2.3.0->voila) (2021.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert<7,>=6.4.5->voila) (2.3.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hp\\anaconda3\\lib\\site-packages (from bleach->nbconvert<7,>=6.4.5->voila) (0.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging->jupyter-server<2.0.0,>=0.3.0->voila) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->jupyterlab-server<3,>=2.3.0->voila) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->jupyterlab-server<3,>=2.3.0->voila) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->jupyterlab-server<3,>=2.3.0->voila) (1.26.8)\n",
      "Installing collected packages: MarkupSafe, tinycss2, pywinpty, jinja2, nbconvert, websockets, voila\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: pywinpty\n",
      "    Found existing installation: pywinpty 2.0.2\n",
      "    Uninstalling pywinpty-2.0.2:\n",
      "      Successfully uninstalled pywinpty-2.0.2\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 2.11.3\n",
      "    Uninstalling Jinja2-2.11.3:\n",
      "      Successfully uninstalled Jinja2-2.11.3\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.2.0\n",
      "    Uninstalling nbconvert-6.2.0:\n",
      "      Successfully uninstalled nbconvert-6.2.0\n",
      "Successfully installed MarkupSafe-2.1.1 jinja2-3.1.1 nbconvert-6.5.0 pywinpty-1.1.6 tinycss2-1.1.1 voila-0.3.5 websockets-10.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cookiecutter 1.7.2 requires Jinja2<3.0.0, but you have jinja2 3.1.1 which is incompatible.\n",
      "cookiecutter 1.7.2 requires MarkupSafe<2.0.0, but you have markupsafe 2.1.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d75b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
